{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Vhlx6KD5wkCS"
      },
      "outputs": [],
      "source": [
        "# !pip install -q \"arize-phoenix>=8.0.0\" datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install -U dspy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "DdQ6pTs9x-zZ",
        "outputId": "8ae734b2-35bc-4139-cc53-c1f62c7532fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nimport os\\nfrom getpass import getpass\\n\\nos.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"https://app.phoenix.arize.com\"\\nif not os.environ.get(\"PHOENIX_CLIENT_HEADERS\"):\\n    os.environ[\"PHOENIX_CLIENT_HEADERS\"] = \"api_key=\" + getpass(\"Enter your Phoenix API key: \")\\n\\nif not os.environ.get(\"OPENAI_API_KEY\"):\\n    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\\n'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"https://app.phoenix.arize.com\"\n",
        "if not os.environ.get(\"PHOENIX_CLIENT_HEADERS\"):\n",
        "    os.environ[\"PHOENIX_CLIENT_HEADERS\"] = \"api_key=\" + getpass(\"Enter your Phoenix API key: \")\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting dspy\n",
            "  Using cached dspy-2.6.10-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: backoff in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (2.2.1)\n",
            "Requirement already satisfied: joblib~=1.3 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (1.4.2)\n",
            "Requirement already satisfied: openai in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (1.65.3)\n",
            "Requirement already satisfied: pandas in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (2.2.3)\n",
            "Requirement already satisfied: regex in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (2024.11.6)\n",
            "Requirement already satisfied: ujson in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (5.10.0)\n",
            "Requirement already satisfied: tqdm in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (4.67.0)\n",
            "Requirement already satisfied: datasets<3.0.0,>=2.14.6 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (2.21.0)\n",
            "Requirement already satisfied: requests in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (2.32.3)\n",
            "Requirement already satisfied: optuna in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (4.2.1)\n",
            "Requirement already satisfied: pydantic~=2.0 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (3.1.4)\n",
            "Requirement already satisfied: magicattr~=0.1.6 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (0.1.6)\n",
            "Requirement already satisfied: litellm<2.0.0,>=1.59.8 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (1.62.1)\n",
            "Requirement already satisfied: diskcache in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (5.6.3)\n",
            "Requirement already satisfied: json-repair in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (0.39.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (9.0.0)\n",
            "Requirement already satisfied: anyio in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (4.6.2.post1)\n",
            "Requirement already satisfied: asyncer==0.0.8 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (0.0.8)\n",
            "Requirement already satisfied: cachetools in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (5.5.0)\n",
            "Requirement already satisfied: cloudpickle in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from dspy) (3.1.1)\n",
            "Requirement already satisfied: idna>=2.8 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from anyio->dspy) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from anyio->dspy) (1.3.1)\n",
            "Requirement already satisfied: filelock in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from datasets<3.0.0,>=2.14.6->dspy) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from datasets<3.0.0,>=2.14.6->dspy) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from datasets<3.0.0,>=2.14.6->dspy) (18.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from datasets<3.0.0,>=2.14.6->dspy) (0.3.8)\n",
            "Requirement already satisfied: xxhash in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from datasets<3.0.0,>=2.14.6->dspy) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from datasets<3.0.0,>=2.14.6->dspy) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<3.0.0,>=2.14.6->dspy) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from datasets<3.0.0,>=2.14.6->dspy) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from datasets<3.0.0,>=2.14.6->dspy) (0.26.2)\n",
            "Requirement already satisfied: packaging in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from datasets<3.0.0,>=2.14.6->dspy) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from datasets<3.0.0,>=2.14.6->dspy) (6.0.2)\n",
            "Requirement already satisfied: click in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from litellm<2.0.0,>=1.59.8->dspy) (8.1.8)\n",
            "Requirement already satisfied: httpx>=0.23.0 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from litellm<2.0.0,>=1.59.8->dspy) (0.27.2)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from litellm<2.0.0,>=1.59.8->dspy) (8.6.1)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from litellm<2.0.0,>=1.59.8->dspy) (4.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from litellm<2.0.0,>=1.59.8->dspy) (1.0.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from litellm<2.0.0,>=1.59.8->dspy) (0.8.0)\n",
            "Requirement already satisfied: tokenizers in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from litellm<2.0.0,>=1.59.8->dspy) (0.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from jinja2->dspy) (3.0.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from openai->dspy) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from openai->dspy) (0.7.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from openai->dspy) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from pydantic~=2.0->dspy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from pydantic~=2.0->dspy) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from requests->dspy) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from requests->dspy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from requests->dspy) (2024.8.30)\n",
            "Requirement already satisfied: colorama in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from tqdm->dspy) (0.4.6)\n",
            "Requirement already satisfied: alembic>=1.5.0 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from optuna->dspy) (1.15.1)\n",
            "Requirement already satisfied: colorlog in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from optuna->dspy) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from optuna->dspy) (2.0.38)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from pandas->dspy) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from pandas->dspy) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from pandas->dspy) (2024.2)\n",
            "Requirement already satisfied: Mako in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from alembic>=1.5.0->optuna->dspy) (1.3.9)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.14.6->dspy) (2.4.8)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.14.6->dspy) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.14.6->dspy) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.14.6->dspy) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.14.6->dspy) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.14.6->dspy) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.14.6->dspy) (1.18.3)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from httpx>=0.23.0->litellm<2.0.0,>=1.59.8->dspy) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from httpcore==1.*->httpx>=0.23.0->litellm<2.0.0,>=1.59.8->dspy) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from importlib-metadata>=6.8.0->litellm<2.0.0,>=1.59.8->dspy) (3.21.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.59.8->dspy) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.59.8->dspy) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.59.8->dspy) (0.23.1)\n",
            "Requirement already satisfied: six>=1.5 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->dspy) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in d:\\anaconda\\envs\\mapcoder\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna->dspy) (3.1.1)\n",
            "Using cached dspy-2.6.10-py3-none-any.whl (260 kB)\n",
            "Installing collected packages: dspy\n",
            "Successfully installed dspy-2.6.10\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install dspy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52F8naxVs3D9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\anaconda\\envs\\mapcoder\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "\n",
        "import openai\n",
        "import dspy\n",
        "import json\n",
        "import re\n",
        "import contextlib\n",
        "import signal\n",
        "from typing import *\n",
        "import random\n",
        "import os\n",
        "from enum import Enum\n",
        "import numpy as np\n",
        "import tqdm\n",
        "from yaml import safe_load\n",
        "from dataclasses import dataclass, field\n",
        "import requests\n",
        "import textwrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aYYPeG4UvnGI"
      },
      "outputs": [],
      "source": [
        "# formatting\n",
        "def parse_code( response: str) -> str:\n",
        "    if \"```\" not in response:\n",
        "        return response\n",
        "\n",
        "    code_pattern = r'```((.|\\n)*?)```'\n",
        "    if \"```Python\" in response:\n",
        "        code_pattern = r'```Python((.|\\n)*?)```'\n",
        "    if \"```Python3\" in response:\n",
        "        code_pattern = r'```Python3((.|\\n)*?)```'\n",
        "    if \"```python\" in response:\n",
        "        code_pattern = r'```python((.|\\n)*?)```'\n",
        "    if \"```python3\" in response:\n",
        "        code_pattern = r'```python3((.|\\n)*?)```'\n",
        "    if \"```C\" in response:\n",
        "        code_pattern = r'```C((.|\\n)*?)```'\n",
        "    if \"```c\" in response:\n",
        "        code_pattern = r'```c((.|\\n)*?)```'\n",
        "    if \"```C++\" in response:\n",
        "        code_pattern = r'```C\\+\\+((.|\\n)*?)```'\n",
        "    if \"```c++\" in response:\n",
        "        code_pattern = r'```c\\+\\+((.|\\n)*?)```'\n",
        "    if \"```Java\" in response:\n",
        "        code_pattern = r'```Java((.|\\n)*?)```'\n",
        "    if \"```java\" in response:\n",
        "        code_pattern = r'```java((.|\\n)*?)```'\n",
        "    if \"```Node\" in response:\n",
        "        code_pattern = r'```Node((.|\\n)*?)```'\n",
        "    if \"```node\" in response:\n",
        "        code_pattern = r'```node((.|\\n)*?)```'\n",
        "    if \"```Rust\" in response:\n",
        "        code_pattern = r'```Rust((.|\\n)*?)```'\n",
        "    if \"```rust\" in response:\n",
        "        code_pattern = r'```rust((.|\\n)*?)```'\n",
        "    if \"```PHP\" in response:\n",
        "        code_pattern = r'```PHP((.|\\n)*?)```'\n",
        "    if \"```php\" in response:\n",
        "        code_pattern = r'```php((.|\\n)*?)```'\n",
        "    if \"```Go\" in response:\n",
        "        code_pattern = r'```Go((.|\\n)*?)```'\n",
        "    if \"```go\" in response:\n",
        "        code_pattern = r'```go((.|\\n)*?)```'\n",
        "    if \"```Ruby\" in response:\n",
        "        code_pattern = r'```Ruby((.|\\n)*?)```'\n",
        "    if \"```ruby\" in response:\n",
        "        code_pattern = r'```ruby((.|\\n)*?)```'\n",
        "    if \"```C#\" in response:\n",
        "        code_pattern = r'```C#((.|\\n)*?)```'\n",
        "    if \"```c#\" in response:\n",
        "        code_pattern = r'```c#((.|\\n)*?)```'\n",
        "    if \"```csharp\" in response:\n",
        "        code_pattern = r'```csharp((.|\\n)*?)```'\n",
        "\n",
        "    code_blocks = re.findall(code_pattern, response, re.DOTALL)\n",
        "\n",
        "    if type(code_blocks[-1]) == tuple or type(code_blocks[-1]) == list:\n",
        "        code_str = \"\\n\".join(code_blocks[-1])\n",
        "    elif type(code_blocks[-1]) == str:\n",
        "        code_str = code_blocks[-1]\n",
        "    else:\n",
        "        code_str = response\n",
        "\n",
        "    return code_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JY-oeVRs_Dc"
      },
      "outputs": [],
      "source": [
        "# api_key\n",
        "openai_api_key = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wzXzMN4dX9AQ"
      },
      "outputs": [],
      "source": [
        "# dspy configuration\n",
        "\n",
        "lm = dspy.LM('openai/gpt-4o-mini', api_key = openai_api_key)\n",
        "dspy.configure(lm = lm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iJLzWTC0g4G1"
      },
      "outputs": [],
      "source": [
        "# OpenAi configuration\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "def gpt_chat(processed_input: List[Dict[str, str]], model=\"gpt-4o-mini\", max_tokens=4096):\n",
        "  \"\"\"\n",
        "  直接调用 OpenAI API 进行对话\n",
        "\n",
        "  :param processed_input: List[Dict[str, str]] - 聊天输入，格式为 [{'role': 'system', 'content': 'Hello'}]\n",
        "  :param model: str - 要使用的 OpenAI 模型，默认为 'gpt-4'\n",
        "  :param max_tokens: int - 生成的最大 token 数量\n",
        "  :return: (str, int, int) - 返回的文本、prompt token 计数、completion token 计数\n",
        "  \"\"\"\n",
        "  response = openai.chat.completions.create(\n",
        "      model=model,\n",
        "      messages=processed_input,\n",
        "      max_tokens=max_tokens\n",
        "  )\n",
        "\n",
        "  return response.choices[0].message.content, response.usage.prompt_tokens, response.usage.completion_tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aXuhU6GFubzS"
      },
      "outputs": [],
      "source": [
        "# Executor utils\n",
        "def timeout_handler(_, __):\n",
        "    raise TimeoutError()\n",
        "\n",
        "import os, json\n",
        "def to_jsonl(dict_data, file_path):\n",
        "    with open(file_path, 'a') as file:\n",
        "        json_line = json.dumps(dict_data)\n",
        "        file.write(json_line + os.linesep)\n",
        "\n",
        "from threading import Thread\n",
        "class PropagatingThread(Thread):\n",
        "    def run(self):\n",
        "        self.exc = None\n",
        "        try:\n",
        "            if hasattr(self, '_Thread__target'):\n",
        "                # Thread uses name mangling prior to Python 3.\n",
        "                self.ret = self._Thread__target(*self._Thread__args, **self._Thread__kwargs)\n",
        "            else:\n",
        "                self.ret = self._target(*self._args, **self._kwargs)\n",
        "        except BaseException as e:\n",
        "            self.exc = e\n",
        "\n",
        "    def join(self, timeout=None):\n",
        "        super(PropagatingThread, self).join(timeout)\n",
        "        if self.exc:\n",
        "            raise self.exc\n",
        "        return self.ret\n",
        "\n",
        "\n",
        "def function_with_timeout(func, args, timeout):\n",
        "    result_container = []\n",
        "\n",
        "    def wrapper():\n",
        "        result_container.append(func(*args))\n",
        "\n",
        "    thread = PropagatingThread(target=wrapper)\n",
        "    thread.start()\n",
        "    thread.join(timeout)\n",
        "\n",
        "    if thread.is_alive():\n",
        "        raise TimeoutError()\n",
        "    else:\n",
        "        return result_container[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-cSpvgI3uPsK"
      },
      "outputs": [],
      "source": [
        "# func evaluate\n",
        "def evaluate_io(\n",
        "  sample_io: list[str],\n",
        "  completion: str,\n",
        "  timeout: int = 5,\n",
        "  stop_early: bool = False,\n",
        "):\n",
        "  test_log = \"\"\n",
        "  passed = True\n",
        "  for io in sample_io:\n",
        "    try:\n",
        "      code = (\"from typing import *\\n\" if \"from typing import *\" not in completion else \"\") + \\\n",
        "        completion + \"\\n\" + io + \"\\n\"\n",
        "      function_with_timeout(\n",
        "        exec,\n",
        "        (code, globals()),\n",
        "        timeout\n",
        "      )\n",
        "      test_log += f\"passed in test case: {io}\\n\"\n",
        "    except Exception as e:\n",
        "      if stop_early:\n",
        "        return False, f\"failed in test case: {io}\\n\"\n",
        "      passed = False\n",
        "      test_log += f\"failed in test case: {io}\\n\"\n",
        "\n",
        "  return passed, test_log\n",
        "\n",
        "\n",
        "def evaluate_io_et(\n",
        "  sample_io: list[str],\n",
        "  completion: str,\n",
        "  timeout: int = 5,\n",
        "  prompt: str = \"\",\n",
        "):\n",
        "  io = \"\\n\".join(sample_io)\n",
        "  try:\n",
        "    code = (\"from typing import *\\n\" if \"from typing import *\" not in completion else \"\") + \\\n",
        "      prompt + completion + \"\\n\" + io + \"\\n\"\n",
        "    function_with_timeout(\n",
        "      exec,\n",
        "      (code, globals()),\n",
        "      timeout\n",
        "    )\n",
        "    return True\n",
        "  except Exception as e:\n",
        "    return False\n",
        "\n",
        "\n",
        "def evaluate_functional_correctness(\n",
        "  problem: Dict,\n",
        "  completion: str,\n",
        "  timeout: int = 5,\n",
        "  test_key: str = \"test\",\n",
        "):\n",
        "  # if problem[\"name\"] == \"mbpp_61_count_Substrings\":\n",
        "  #     pass\n",
        "  try:\n",
        "    code = (\"from typing import *\\n\" if \"from typing import *\" not in completion else \"\") + \\\n",
        "      completion + \"\\n\" + problem[test_key] + \\\n",
        "      \"\\n\" + f\"check({problem['entry_point']})\"\n",
        "\n",
        "    function_with_timeout(\n",
        "      exec,\n",
        "      (code, globals()),\n",
        "      timeout\n",
        "    )\n",
        "    return \"passed\"\n",
        "  except Exception as e:\n",
        "    return f\"failed: {e}\"\n",
        "\n",
        "\n",
        "def evaluate_functional_correctness2(\n",
        "  problem: Dict,\n",
        "  completion: str,\n",
        "  timeout: float = 10,\n",
        ") -> Dict:\n",
        "\n",
        "  check_program = (\n",
        "    # problem[\"prompt\"] +\n",
        "    \"from typing import *\\n\" +\n",
        "    completion + \"\\n\" +\n",
        "    problem[\"test\"] + \"\\n\" +\n",
        "    f\"check({problem['entry_point']})\"\n",
        "  )\n",
        "  # print(check_program)\n",
        "\n",
        "  try:\n",
        "    exec(check_program)\n",
        "    return \"passed\"\n",
        "  except TimeoutException:\n",
        "    return \"timed out\"\n",
        "  except BaseException as e:\n",
        "    return f\"failed: {e}\"\n",
        "\n",
        "\n",
        "class TimeoutException(Exception):\n",
        "  pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5XUlhj0VurWP"
      },
      "outputs": [],
      "source": [
        "def evaluate(\n",
        "  item: dict,\n",
        "  cur_imp: str,\n",
        "  language: str,\n",
        "):\n",
        "  result = evaluate_functional_correctness(\n",
        "    problem=item,\n",
        "    completion=cur_imp\n",
        "  )\n",
        "  return result == \"passed\"\n",
        "\n",
        "def humaneval_evaluate_sample_io(\n",
        "  item: dict,\n",
        "  cur_imp: str,\n",
        "  language: str,\n",
        "):\n",
        "\n",
        "  return evaluate_io(\n",
        "    sample_io=item[\"sample_io_prompt\"],\n",
        "    completion=cur_imp,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xrVGmEy4ITUT"
      },
      "outputs": [],
      "source": [
        "class ExecOutcome(Enum):\n",
        "    PASSED = \"PASSED\"  # code executes and output matches expected output\n",
        "    WRONG_ANSWER = (\n",
        "        \"WRONG_ANSWER\"  # code executes and output does NOT matches expected output\n",
        "    )\n",
        "    TIME_LIMIT_EXCEEDED = \"TIME_LIMIT_EXCEEDED\"  # code executes and didn't exit in time, output is ignored in this case\n",
        "    RUNTIME_ERROR = \"RUNTIME_ERROR\"  # code failed to execute (crashed)\n",
        "    COMPILATION_ERROR = \"COMPILATION_ERROR\"  # code failed to compile\n",
        "    MEMORY_LIMIT_EXCEEDED = (\n",
        "        \"MEMORY_LIMIT_EXCEEDED\"  # code exceeded memory limit during execution\n",
        "    )\n",
        "\n",
        "@dataclass\n",
        "class ExtendedUnittest:\n",
        "    input: str\n",
        "    output: list[str] = field(default_factory=list)\n",
        "    result: str | None = None\n",
        "    exec_outcome: ExecOutcome | None = None\n",
        "\n",
        "    def json(self):\n",
        "        _json = self.__dict__\n",
        "        if self.exec_outcome is not None:\n",
        "            _json[\"exec_outcome\"] = self.exec_outcome.name\n",
        "\n",
        "        return _json\n",
        "\n",
        "    @classmethod\n",
        "    def from_json(cls, _json):\n",
        "        return cls(\n",
        "            input=_json.get(\"input\", \"\"),\n",
        "            output=_json.get(\"output\", list()),\n",
        "            result=_json.get(\"result\", None),\n",
        "            exec_outcome=_json.get(\"exec_outcome\", None),\n",
        "        )\n",
        "\n",
        "\n",
        "class EmptyValueError(Exception):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "\n",
        "class EmptyUnittestError(EmptyValueError):\n",
        "    pass\n",
        "\n",
        "\n",
        "class EmptyLanguageError(EmptyValueError):\n",
        "    pass\n",
        "\n",
        "\n",
        "class EmptySourceCodeError(EmptyValueError):\n",
        "    pass\n",
        "\n",
        "\n",
        "class APICommunication:\n",
        "    _session: requests.Session\n",
        "\n",
        "    def __init__(self, server_url: str = \"http://localhost:5000\"):\n",
        "        self._session = requests.Session()\n",
        "        self.execute_code_url = f\"{server_url}/api/execute_code\"\n",
        "        self.get_runtimes_url = f\"{server_url}/api/all_runtimes\"\n",
        "\n",
        "    def __enter__(self):\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, *args):\n",
        "        self._session.close()\n",
        "\n",
        "    def get_runtimes(self):\n",
        "        return self._session.get(self.get_runtimes_url).json()\n",
        "\n",
        "    def execute_code(\n",
        "        self,\n",
        "        language: str,\n",
        "        source_code: str,\n",
        "        unittests: list[dict],\n",
        "        limits: dict | None,\n",
        "        block_network: bool = True,\n",
        "        stop_on_first_fail: bool = True,\n",
        "        use_sanitizer: bool = False,\n",
        "        compiler_program_name: str | None = None,\n",
        "        compiler_flags: str | None = None,\n",
        "        interpreter_cmd: str | None = None,\n",
        "        interpreter_flags: str | None = None,\n",
        "        sample_id: int | None = None,\n",
        "        task_id: str | int | None = None,\n",
        "    ) -> tuple[list[ExtendedUnittest], int | None, str | int | None]:\n",
        "        if language is None:\n",
        "            raise EmptyLanguageError\n",
        "\n",
        "        if source_code is None:\n",
        "            raise EmptySourceCodeError\n",
        "\n",
        "        if unittests is None or len(unittests) == 0:\n",
        "            raise EmptyUnittestError\n",
        "\n",
        "        request_body = dict(\n",
        "            language=language,\n",
        "            source_code=source_code,\n",
        "            unittests=unittests,\n",
        "            limits=limits if isinstance(limits, dict) else dict(),\n",
        "            compile_cmd=compiler_program_name,\n",
        "            compile_flags=compiler_flags,\n",
        "            execute_cmd=interpreter_cmd,\n",
        "            execute_flags=interpreter_flags,\n",
        "            block_network=block_network,\n",
        "            stop_on_first_fail=stop_on_first_fail,\n",
        "            use_sanitizer=use_sanitizer,\n",
        "        )\n",
        "        json_response = self._session.post(\n",
        "            self.execute_code_url,\n",
        "            json=request_body,\n",
        "            headers={\"Content-Type\": \"application/json\"},\n",
        "        ).json()\n",
        "\n",
        "        if \"data\" not in json_response:\n",
        "            return \"error\", sample_id, task_id\n",
        "\n",
        "        return (\n",
        "            json_response[\"data\"],\n",
        "            sample_id,\n",
        "            task_id,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ihS5vObzHwcj"
      },
      "outputs": [],
      "source": [
        "\n",
        "LANGUAGE_MAPPING = {\n",
        "    \"Python\": \"Python 3\",\n",
        "    \"Python3\": \"Python 3\",\n",
        "    \"python\": \"Python 3\",\n",
        "    \"C#\": \"C# 10\",\n",
        "    \"NET-CORE\": \".NET Core C#\",\n",
        "    # \"Node\": \"Node.js\",\n",
        "    \"Rust\": \"Rust\",\n",
        "    # \"Java\":\"Java 17\",\n",
        "    \"PHP\": \"PHP\",\n",
        "    \"Go\": \"Go\",\n",
        "    \"Ruby\": \"Ruby\",\n",
        "    \"C++\": \"GNU C++17\",\n",
        "    \"C\": \"GNU C\"\n",
        "}\n",
        "\n",
        "colab_limits_by_lang_cfg_file = \"/content/limits_by_lang.yaml\"\n",
        "local_limits_by_lang_cfg_file = r\"C:\\Users\\31646\\Desktop\\LLM_Project\\MapCoder\\src\\evaluations\\limits_by_lang.yaml\"\n",
        "\n",
        "limits_by_lang_cfg_file = local_limits_by_lang_cfg_file\n",
        "\n",
        "assert os.path.exists(\n",
        "    limits_by_lang_cfg_file), \"Need resource limit defaults for all runtimes, provide the path to default 'limits_by_lang.yaml' or to the modified one.\"\n",
        "\n",
        "with open(limits_by_lang_cfg_file) as limit_cfg_rp:\n",
        "    limits_by_lang = safe_load(limit_cfg_rp)\n",
        "\n",
        "\n",
        "api_comm = APICommunication()\n",
        "\n",
        "\n",
        "def contest_evaluate(\n",
        "    generated_code: str,\n",
        "    lang: str,\n",
        "    id: int,\n",
        "    tests: List[dict],\n",
        "):\n",
        "    assert lang in LANGUAGE_MAPPING, f\"language must be inside the supported language list: {LANGUAGE_MAPPING.keys()}\"\n",
        "\n",
        "    results, _, _ = api_comm.execute_code(\n",
        "        language=LANGUAGE_MAPPING[lang],\n",
        "        source_code=generated_code,\n",
        "        unittests=tests,\n",
        "        limits=limits_by_lang[LANGUAGE_MAPPING[lang]],\n",
        "        task_id=id,\n",
        "    )\n",
        "\n",
        "    if results == \"error\":\n",
        "        return False\n",
        "\n",
        "    passed = True\n",
        "    for result in results:\n",
        "        if result['exec_outcome'] != ExecOutcome.PASSED.value:\n",
        "            passed = False\n",
        "            break\n",
        "\n",
        "    return passed\n",
        "\n",
        "\n",
        "def contest_evaluate_public_tests(\n",
        "    generated_code: str,\n",
        "    lang: str,\n",
        "    id: int,\n",
        "    tests: List[dict],\n",
        "):\n",
        "    results, _, _ = api_comm.execute_code(\n",
        "        language=LANGUAGE_MAPPING[lang],\n",
        "        source_code=generated_code,\n",
        "        unittests=tests,\n",
        "        limits=limits_by_lang[LANGUAGE_MAPPING[lang]],\n",
        "        task_id=id,\n",
        "        stop_on_first_fail=False\n",
        "    )\n",
        "\n",
        "    passed = True\n",
        "    passed_feedback = []\n",
        "    failed_feedback = []\n",
        "\n",
        "    idx = 0\n",
        "    try:\n",
        "        for idx, result in enumerate(results):\n",
        "            output = str(result['result'])\n",
        "            if len(output) > 500:\n",
        "                output = output[:500] + \"...\"\n",
        "            test_case = f\"Input:\\n{tests[idx]['input']}\\nExpected Output:\\n{tests[idx]['output'][0]}\\nYour Output:\\n{output}\\n\"\n",
        "            if result['exec_outcome'] == ExecOutcome.PASSED.value:\n",
        "                passed_feedback.append(test_case)\n",
        "            if result['exec_outcome'] != ExecOutcome.PASSED.value:\n",
        "                failed_feedback.append(test_case)\n",
        "                passed = False\n",
        "    except:\n",
        "        passed = False\n",
        "        test_cases = []\n",
        "        for i in range(idx, len(tests)):\n",
        "            test_case = f\"Input:\\n{tests[i]['input']}\\nExpected Output:\\n{tests[i]['output'][0]}\\n\"\n",
        "            test_cases.append(test_case)\n",
        "\n",
        "        failed_feedback.extend(test_cases)\n",
        "\n",
        "    passed_feedback = '\\n'.join(passed_feedback) if len(passed_feedback) > 0 else \"No test cases passed.\"\n",
        "    failed_feedback = '\\n'.join(failed_feedback)\n",
        "    feedback = f'## Tested passed:\\n{passed_feedback}\\n\\n## Tests failed:\\n{failed_feedback}'\n",
        "\n",
        "    return passed, feedback\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fRqwuzDjetbL"
      },
      "outputs": [],
      "source": [
        "def coding_agent_prompt(algorithm_prompt, task, planning, sample_io_prompt, std_input_prompt):\n",
        "  return [\n",
        "    {\n",
        "\"role\": \"user\",\n",
        "\"content\":\n",
        "f\"\"\"Given a competitive programming problem, generate python code to solve the problem.\n",
        "{algorithm_prompt}\n",
        "## Problem to be solved:\n",
        "{task}\n",
        "## Planning:\n",
        "{planning}\n",
        "{sample_io_prompt}\n",
        "## Let's think step by step.\n",
        "----------------\n",
        "Important:\n",
        "{std_input_prompt}\n",
        "## Your response must contain only the python code to solve this problem.\n",
        "Do not add extra explanation or words.\n",
        "\"\"\"\n",
        "  }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eH0_R9C7k4NC",
        "outputId": "bab78af9-3e58-4640-da17-982a6353ae82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test', 'sample_io'])\n"
          ]
        }
      ],
      "source": [
        "# Load HumanEval dataset\n",
        "def read_jsonl(filename):\n",
        "  \"\"\"Reads a jsonl file and yields each line as a dictionary\"\"\"\n",
        "  lines = []\n",
        "  with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
        "      for line in file:\n",
        "          lines.append(json.loads(line))\n",
        "  return lines\n",
        "\n",
        "# Humaneval\n",
        "from datasets import load_dataset\n",
        "\n",
        "local_path = r\"C:\\Users\\31646\\Desktop\\LLM_Project\\MapCoder\\data\\HumanEval\\HumanEvalWST.jsonl\"\n",
        "colab_path = \"/content/HumanEvalWST.jsonl\"\n",
        "\n",
        "path = local_path\n",
        "\n",
        "humaneval_ds = read_jsonl(path)\n",
        "print(humaneval_ds[0].keys())\n",
        "\n",
        "# select random 20% as a trial\n",
        "trainset = humaneval_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "YRUsFpAWfRCJ"
      },
      "outputs": [],
      "source": [
        "def get_sample_io_str(sample_io: any) -> str:\n",
        "    if len(sample_io) > 0:\n",
        "        if type(sample_io[0]) == str:\n",
        "            return \"\\n\".join(sample_io)\n",
        "        if type(sample_io[0]) == dict:\n",
        "            return \"\\n\".join([f\"Input:\\n{io['input']}\\nExpected output:\\n{io['output'][0]}\" for io in sample_io])\n",
        "    return sample_io\n",
        "\n",
        "def humaneval_metric(example, pred, trace=None):\n",
        "  sample_io_prompt = f\"## Sample Test cases: \\n{get_sample_io_str(example['sample_io_prompt'])}\\n\"\n",
        "  task = example['task']\n",
        "  algorithm_prompt = \"\"\n",
        "  std_input_prompt = \"\"\n",
        "  for i in range(0,3):\n",
        "    plan = getattr(pred, f\"plan_{i+1}\")\n",
        "    coding_prompt = coding_agent_prompt(algorithm_prompt, task, plan, sample_io_prompt, std_input_prompt)\n",
        "\n",
        "    code, _, _ = gpt_chat(coding_prompt)\n",
        "    code = parse_code(code)\n",
        "    passed, test_log = humaneval_evaluate_sample_io(example, code, \"python\")\n",
        "\n",
        "    if passed:\n",
        "      return passed\n",
        "  return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "YB6gXCFynnkr"
      },
      "outputs": [],
      "source": [
        "class GeneratePlans(dspy.Signature):\n",
        "    \"\"\"\n",
        "    Given the task description and the sample input-output pairs, generate a structured plan consisting of three actionable steps (Plan 1, Plan 2, Plan 3) to solve the task effectively. \n",
        "    Ensure that each plan outlines specific actions that need to be taken to implement the solution correctly\n",
        "    \"\"\"\n",
        "    task = dspy.InputField(format=str)\n",
        "    sample_io_prompt = dspy.InputField(format=str)\n",
        "    plan_1 = dspy.OutputField(format=str)\n",
        "    plan_2 = dspy.OutputField(format=str)\n",
        "    plan_3 = dspy.OutputField(format=str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "-QemA6cu0PwC"
      },
      "outputs": [],
      "source": [
        "generatePlans = dspy.Predict(GeneratePlans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5O8qqh0wB-o",
        "outputId": "11ea8ff6-75d0-4650-8a4f-89860515a8c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example({'id': 'HumanEval/0', 'task': 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n', 'sample_io_prompt': ['assert has_close_elements([1.0, 2.0, 3.0], 0.5) == False', 'assert has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) == True'], 'plan_1': '', 'plan_2': '', 'plan_3': ''}) (input_keys={'sample_io_prompt', 'task'})\n",
            "['assert has_close_elements([1.0, 2.0, 3.0], 0.5) == False', 'assert has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) == True']\n",
            "from typing import List\n",
            "\n",
            "\n",
            "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
            "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
            "    given threshold.\n",
            "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
            "    False\n",
            "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
            "    True\n",
            "    \"\"\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_data = []\n",
        "for item in trainset:\n",
        "  example = dspy.Example(id = item['task_id'],task=item['prompt'], sample_io_prompt = item['sample_io'], plan_1 = \"\", plan_2 = \"\", plan_3 = \"\").with_inputs(\"task\", \"sample_io_prompt\")\n",
        "  train_data.append(example)\n",
        "\n",
        "print(train_data[0])\n",
        "print(train_data[0]['sample_io_prompt'])\n",
        "print(train_data[0]['task'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq1o3txk0Srn",
        "outputId": "9d5e00ae-4160-4b3a-9c54-d13fedeb4b21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 08:56:21 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "RUNNING WITH THE FOLLOWING LIGHT AUTO RUN SETTINGS:\n",
            "num_trials: 7\n",
            "minibatch: True\n",
            "num_candidates: 5\n",
            "valset size: 100\n",
            "\n",
            "2025/03/06 08:56:23 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
            "2025/03/06 08:56:23 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
            "\n",
            "2025/03/06 08:56:23 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=5 sets of demonstrations...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapping set 1/5\n",
            "Bootstrapping set 2/5\n",
            "Bootstrapping set 3/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 4/33 [00:25<03:01,  6.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
            "Bootstrapping set 4/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 3/33 [00:23<03:54,  7.82s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
            "Bootstrapping set 5/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 2/33 [00:06<01:43,  3.35s/it]\n",
            "2025/03/06 08:57:18 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
            "2025/03/06 08:57:18 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 08:57:33 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "Proposing instructions...\n",
            "\n",
            "2025/03/06 08:58:15 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
            "\n",
            "2025/03/06 08:58:15 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Given the task description and the sample input-output pairs, generate a structured plan consisting of three actionable steps (Plan 1, Plan 2, Plan 3) to solve the task effectively. \n",
            "Ensure that each plan outlines specific actions that need to be taken to implement the solution correctly\n",
            "\n",
            "2025/03/06 08:58:15 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Using the provided task description and sample input-output pairs, create a detailed plan comprising three actionable steps (Plan 1, Plan 2, Plan 3) to effectively solve the task. Each plan should specify the actions required to implement the solution accurately, ensuring clarity and systematic development.\n",
            "\n",
            "2025/03/06 08:58:15 INFO dspy.teleprompt.mipro_optimizer_v2: 2: Based on the provided task description and sample input-output pairs, create a structured plan consisting of three actionable steps (Plan 1, Plan 2, Plan 3) to effectively solve the task. Each plan should clearly outline specific actions to be taken for implementing the solution correctly, ensuring clarity and systematic problem-solving.\n",
            "\n",
            "2025/03/06 08:58:15 INFO dspy.teleprompt.mipro_optimizer_v2: 3: Based on the provided task description and sample input-output pairs, please generate a structured plan consisting of three actionable steps (Plan 1, Plan 2, Plan 3) to effectively solve the task. Each plan should detail specific actions to be taken, ensuring that the implementation is clear, systematic, and accounts for edge cases. Include any necessary validations, iterations, and return statements in your plans to guarantee correctness and reliability of the function.\n",
            "\n",
            "2025/03/06 08:58:15 INFO dspy.teleprompt.mipro_optimizer_v2: 4: Given the task description and the sample input-output pairs, generate a structured plan consisting of three actionable steps (Plan 1, Plan 2, Plan 3) to solve the task effectively. Each plan should clearly outline specific actions that need to be taken to implement the solution correctly, including any necessary calculations, logical comparisons, or iterations. Additionally, consider edge cases and potential optimizations to ensure robustness and efficiency in the implementation.\n",
            "\n",
            "2025/03/06 08:58:15 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2025/03/06 08:58:15 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
            "2025/03/06 08:58:15 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
            "\n",
            "2025/03/06 08:58:15 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 8 - Full Evaluation of Default Program ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 86.00 / 100 (86.0%): 100%|██████████| 100/100 [01:51<00:00,  1.12s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 09:00:07 INFO dspy.evaluate.evaluate: Average Metric: 86 / 100 (86.0%)\n",
            "2025/03/06 09:00:07 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 86.0\n",
            "\n",
            "d:\\anaconda\\envs\\mapcoder\\Lib\\site-packages\\optuna\\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "2025/03/06 09:00:07 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 2 / 8 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 22.00 / 25 (88.0%): 100%|██████████| 25/25 [00:44<00:00,  1.79s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 09:00:51 INFO dspy.evaluate.evaluate: Average Metric: 22 / 25 (88.0%)\n",
            "2025/03/06 09:00:51 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 88.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/03/06 09:00:51 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [88.0]\n",
            "2025/03/06 09:00:51 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [86.0]\n",
            "2025/03/06 09:00:51 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 86.0\n",
            "2025/03/06 09:00:51 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/03/06 09:00:51 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 3 / 8 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 18.00 / 25 (72.0%): 100%|██████████| 25/25 [00:34<00:00,  1.37s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 09:01:26 INFO dspy.evaluate.evaluate: Average Metric: 18 / 25 (72.0%)\n",
            "2025/03/06 09:01:26 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 72.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/03/06 09:01:26 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [88.0, 72.0]\n",
            "2025/03/06 09:01:26 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [86.0]\n",
            "2025/03/06 09:01:26 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 86.0\n",
            "2025/03/06 09:01:26 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/03/06 09:01:26 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 4 / 8 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 21.00 / 25 (84.0%): 100%|██████████| 25/25 [00:50<00:00,  2.00s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 09:02:16 INFO dspy.evaluate.evaluate: Average Metric: 21 / 25 (84.0%)\n",
            "2025/03/06 09:02:16 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 84.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/03/06 09:02:16 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [88.0, 72.0, 84.0]\n",
            "2025/03/06 09:02:16 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [86.0]\n",
            "2025/03/06 09:02:16 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 86.0\n",
            "2025/03/06 09:02:16 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/03/06 09:02:16 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 5 / 8 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 22.00 / 25 (88.0%): 100%|██████████| 25/25 [00:33<00:00,  1.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 09:02:49 INFO dspy.evaluate.evaluate: Average Metric: 22 / 25 (88.0%)\n",
            "2025/03/06 09:02:49 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 88.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/03/06 09:02:49 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [88.0, 72.0, 84.0, 88.0]\n",
            "2025/03/06 09:02:49 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [86.0]\n",
            "2025/03/06 09:02:49 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 86.0\n",
            "2025/03/06 09:02:49 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/03/06 09:02:49 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 6 / 8 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 23.00 / 25 (92.0%): 100%|██████████| 25/25 [00:41<00:00,  1.68s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 09:03:31 INFO dspy.evaluate.evaluate: Average Metric: 23 / 25 (92.0%)\n",
            "2025/03/06 09:03:31 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 92.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 3'].\n",
            "2025/03/06 09:03:31 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [88.0, 72.0, 84.0, 88.0, 92.0]\n",
            "2025/03/06 09:03:31 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [86.0]\n",
            "2025/03/06 09:03:31 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 86.0\n",
            "2025/03/06 09:03:31 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/03/06 09:03:31 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 7 / 8 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 21.00 / 25 (84.0%): 100%|██████████| 25/25 [00:37<00:00,  1.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 09:04:09 INFO dspy.evaluate.evaluate: Average Metric: 21 / 25 (84.0%)\n",
            "2025/03/06 09:04:09 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 84.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/03/06 09:04:09 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [88.0, 72.0, 84.0, 88.0, 92.0, 84.0]\n",
            "2025/03/06 09:04:09 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [86.0]\n",
            "2025/03/06 09:04:09 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 86.0\n",
            "2025/03/06 09:04:09 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/03/06 09:04:09 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 8 / 8 - Full Evaluation =====\n",
            "2025/03/06 09:04:09 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 92.0) from minibatch trials...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 87.00 / 100 (87.0%): 100%|██████████| 100/100 [02:21<00:00,  1.42s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 09:06:31 INFO dspy.evaluate.evaluate: Average Metric: 87 / 100 (87.0%)\n",
            "2025/03/06 09:06:31 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mNew best full eval score!\u001b[0m Score: 87.0\n",
            "2025/03/06 09:06:31 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [86.0, 87.0]\n",
            "2025/03/06 09:06:31 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 87.0\n",
            "2025/03/06 09:06:31 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
            "2025/03/06 09:06:31 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2025/03/06 09:06:31 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 87.0!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "tp = dspy.MIPROv2(metric=humaneval_metric, auto='light')\n",
        "optimized = tp.compile(generatePlans, trainset=train_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh5T-wHy-hDt",
        "outputId": "022751f6-7a33-4e38-8e92-c888b6ba8baf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StringSignature(task, sample_io_prompt -> plan_1, plan_2, plan_3\n",
            "    instructions='Given the task description and the sample input-output pairs, generate a structured plan consisting of three actionable steps (Plan 1, Plan 2, Plan 3) to solve the task effectively. Each plan should clearly outline specific actions that need to be taken to implement the solution correctly, including any necessary calculations, logical comparisons, or iterations. Additionally, consider edge cases and potential optimizations to ensure robustness and efficiency in the implementation.'\n",
            "    task = Field(annotation=str required=True json_schema_extra={'format': <class 'str'>, '__dspy_field_type': 'input', 'prefix': 'Task:', 'desc': '${task}'})\n",
            "    sample_io_prompt = Field(annotation=str required=True json_schema_extra={'format': <class 'str'>, '__dspy_field_type': 'input', 'prefix': 'Sample Io Prompt:', 'desc': '${sample_io_prompt}'})\n",
            "    plan_1 = Field(annotation=str required=True json_schema_extra={'format': <class 'str'>, '__dspy_field_type': 'output', 'prefix': 'Plan 1:', 'desc': '${plan_1}'})\n",
            "    plan_2 = Field(annotation=str required=True json_schema_extra={'format': <class 'str'>, '__dspy_field_type': 'output', 'prefix': 'Plan 2:', 'desc': '${plan_2}'})\n",
            "    plan_3 = Field(annotation=str required=True json_schema_extra={'format': <class 'str'>, '__dspy_field_type': 'output', 'prefix': 'Plan 3:', 'desc': '${plan_3}'})\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(optimized.signature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Given the task description and the sample input-output pairs, generate a\n",
            "structured plan consisting of three actionable steps (Plan 1, Plan 2, Plan 3) to\n",
            "solve the task effectively. Each plan should clearly outline specific actions\n",
            "that need to be taken to implement the solution correctly, including any\n",
            "necessary calculations, logical comparisons, or iterations. Additionally,\n",
            "consider edge cases and potential optimizations to ensure robustness and\n",
            "efficiency in the implementation.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "wrapped_text = textwrap.fill(optimized.signature.instructions, width=80)  # 80 可调整\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLhwS5moAtxi",
        "outputId": "a3b76dbf-41ab-4d41-ac62-c9debaf26216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[34m[2025-03-06T07:19:04.608689]\u001b[0m\n",
            "\n",
            "\u001b[31mSystem message:\u001b[0m\n",
            "\n",
            "Your input fields are:\n",
            "1. `task` (str)\n",
            "2. `sample_io_prompt` (str)\n",
            "\n",
            "Your output fields are:\n",
            "1. `plan_1` (str)\n",
            "2. `plan_2` (str)\n",
            "3. `plan_3` (str)\n",
            "\n",
            "All interactions will be structured in the following way, with the appropriate values filled in.\n",
            "\n",
            "[[ ## task ## ]]\n",
            "{task}\n",
            "\n",
            "[[ ## sample_io_prompt ## ]]\n",
            "{sample_io_prompt}\n",
            "\n",
            "[[ ## plan_1 ## ]]\n",
            "{plan_1}\n",
            "\n",
            "[[ ## plan_2 ## ]]\n",
            "{plan_2}\n",
            "\n",
            "[[ ## plan_3 ## ]]\n",
            "{plan_3}\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "In adhering to this structure, your objective is: \n",
            "        Given the fields `task`, `sample_io_prompt`, produce the fields `plan_1`, `plan_2`, `plan_3`.\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## task ## ]]\n",
            "\n",
            "def count_upper(s):\n",
            "    \"\"\"\n",
            "    Given a string s, count the number of uppercase vowels in even indices.\n",
            "    \n",
            "    For example:\n",
            "    count_upper('aBCdEf') returns 1\n",
            "    count_upper('abcdefg') returns 0\n",
            "    count_upper('dBBE') returns 0\n",
            "    \"\"\"\n",
            "\n",
            "\n",
            "[[ ## sample_io_prompt ## ]]\n",
            "[1] «assert count_upper('aBCdEf') == 1»\n",
            "[2] «assert count_upper('abcdefg') == 0»\n",
            "[3] «assert count_upper('dBBE') == 0»\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `[[ ## plan_1 ## ]]`, then `[[ ## plan_2 ## ]]`, then `[[ ## plan_3 ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## plan_1 ## ]]\n",
            "\n",
            "\n",
            "[[ ## plan_2 ## ]]\n",
            "\n",
            "\n",
            "[[ ## plan_3 ## ]]\n",
            "\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## task ## ]]\n",
            "from typing import List\n",
            "\n",
            "\n",
            "def remove_duplicates(numbers: List[int]) -> List[int]:\n",
            "    \"\"\" From a list of integers, remove all elements that occur more than once.\n",
            "    Keep order of elements left the same as in the input.\n",
            "    >>> remove_duplicates([1, 2, 3, 2, 4])\n",
            "    [1, 3, 4]\n",
            "    \"\"\"\n",
            "\n",
            "\n",
            "[[ ## sample_io_prompt ## ]]\n",
            "«assert remove_duplicates([1, 2, 3, 2, 4]) == [1, 3, 4]»\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `[[ ## plan_1 ## ]]`, then `[[ ## plan_2 ## ]]`, then `[[ ## plan_3 ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## plan_1 ## ]]\n",
            "\n",
            "\n",
            "[[ ## plan_2 ## ]]\n",
            "\n",
            "\n",
            "[[ ## plan_3 ## ]]\n",
            "\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## task ## ]]\n",
            "\n",
            "\n",
            "def remove_vowels(text):\n",
            "    \"\"\"\n",
            "    remove_vowels is a function that takes string and returns string without vowels.\n",
            "    >>> remove_vowels('')\n",
            "    ''\n",
            "    >>> remove_vowels(\"abcdef\\nghijklm\")\n",
            "    'bcdf\\nghjklm'\n",
            "    >>> remove_vowels('abcdef')\n",
            "    'bcdf'\n",
            "    >>> remove_vowels('aaaaa')\n",
            "    ''\n",
            "    >>> remove_vowels('aaBAA')\n",
            "    'B'\n",
            "    >>> remove_vowels('zbcd')\n",
            "    'zbcd'\n",
            "    \"\"\"\n",
            "\n",
            "\n",
            "[[ ## sample_io_prompt ## ]]\n",
            "[1] «assert remove_vowels('') == ''»\n",
            "[2] «assert remove_vowels(\"abcdef\\nghijklm\") == 'bcdf\\nghjklm'»\n",
            "[3] «assert remove_vowels('abcdef') == 'bcdf'»\n",
            "[4] «assert remove_vowels('aaaaa') == ''»\n",
            "[5] «assert remove_vowels('aaBAA') == 'B'»\n",
            "[6] «assert remove_vowels('zbcd') == 'zbcd'»\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `[[ ## plan_1 ## ]]`, then `[[ ## plan_2 ## ]]`, then `[[ ## plan_3 ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## plan_1 ## ]]\n",
            "\n",
            "\n",
            "[[ ## plan_2 ## ]]\n",
            "\n",
            "\n",
            "[[ ## plan_3 ## ]]\n",
            "\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## task ## ]]\n",
            "\n",
            "def is_nested(string):\n",
            "    '''\n",
            "    Create a function that takes a string as input which contains only square brackets.\n",
            "    The function should return True if and only if there is a valid subsequence of brackets \n",
            "    where at least one bracket in the subsequence is nested.\n",
            "\n",
            "    is_nested('[[]]') ➞ True\n",
            "    is_nested('[]]]]]]][[[[[]') ➞ False\n",
            "    is_nested('[][]') ➞ False\n",
            "    is_nested('[]') ➞ False\n",
            "    is_nested('[[][]]') ➞ True\n",
            "    is_nested('[[]][]') ➞ True\n",
            "    '''\n",
            "\n",
            "\n",
            "[[ ## sample_io_prompt ## ]]\n",
            "[1] «assert is_nested('[[]]') == True»\n",
            "[2] «assert is_nested('[]]]]]]][[[[[]') == False»\n",
            "[3] «assert is_nested('[][]') == False»\n",
            "[4] «assert is_nested('[]') == False»\n",
            "[5] «assert is_nested('[[][]]') == True»\n",
            "[6] «assert is_nested('[[]][]') == True»\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `[[ ## plan_1 ## ]]`, then `[[ ## plan_2 ## ]]`, then `[[ ## plan_3 ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## plan_1 ## ]]\n",
            "\n",
            "\n",
            "[[ ## plan_2 ## ]]\n",
            "\n",
            "\n",
            "[[ ## plan_3 ## ]]\n",
            "\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## task ## ]]\n",
            "\n",
            "\n",
            "def sum_squares(lst):\n",
            "    \"\"\"You are given a list of numbers.\n",
            "    You need to return the sum of squared numbers in the given list,\n",
            "    round each element in the list to the upper int(Ceiling) first.\n",
            "    Examples:\n",
            "    For lst = [1,2,3] the output should be 14\n",
            "    For lst = [1,4,9] the output should be 98\n",
            "    For lst = [1,3,5,7] the output should be 84\n",
            "    For lst = [1.4,4.2,0] the output should be 29\n",
            "    For lst = [-2.4,1,1] the output should be 6\n",
            "    \n",
            "\n",
            "    \"\"\"\n",
            "\n",
            "\n",
            "[[ ## sample_io_prompt ## ]]\n",
            "[1] «assert sum_squares([1,2,3])==14»\n",
            "[2] «assert sum_squares([1,4,9])==98»\n",
            "[3] «assert sum_squares([1,3,5,7])==84»\n",
            "[4] «assert sum_squares([1.4,4.2,0])==29»\n",
            "[5] «assert sum_squares([-2.4,1,1])==6»\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `[[ ## plan_1 ## ]]`, then `[[ ## plan_2 ## ]]`, then `[[ ## plan_3 ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## plan_1 ## ]]\n",
            "\n",
            "\n",
            "[[ ## plan_2 ## ]]\n",
            "\n",
            "\n",
            "[[ ## plan_3 ## ]]\n",
            "\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## task ## ]]\n",
            "from typing import List\n",
            "\n",
            "\n",
            "def filter_by_substring(strings: List[str], substring: str) -> List[str]:\n",
            "    \"\"\" Filter an input list of strings only for ones that contain given substring\n",
            "    >>> filter_by_substring([], 'a')\n",
            "    []\n",
            "    >>> filter_by_substring(['abc', 'bacd', 'cde', 'array'], 'a')\n",
            "    ['abc', 'bacd', 'array']\n",
            "    \"\"\"\n",
            "\n",
            "\n",
            "[[ ## sample_io_prompt ## ]]\n",
            "[1] «assert filter_by_substring([], 'a') == []»\n",
            "[2] «assert filter_by_substring(['abc', 'bacd', 'cde', 'array'], 'a') == ['abc', 'bacd', 'array']»\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `[[ ## plan_1 ## ]]`, then `[[ ## plan_2 ## ]]`, then `[[ ## plan_3 ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## plan_1 ## ]]\n",
            "\n",
            "\n",
            "[[ ## plan_2 ## ]]\n",
            "\n",
            "\n",
            "[[ ## plan_3 ## ]]\n",
            "\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## task ## ]]\n",
            "from typing import List\n",
            "\n",
            "\n",
            "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
            "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
            "    given threshold.\n",
            "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
            "    False\n",
            "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
            "    True\n",
            "    \"\"\"\n",
            "\n",
            "\n",
            "[[ ## sample_io_prompt ## ]]\n",
            "[1] «assert has_close_elements([1.0, 2.0, 3.0], 0.5) == False»\n",
            "[2] «assert has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) == True»\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `[[ ## plan_1 ## ]]`, then `[[ ## plan_2 ## ]]`, then `[[ ## plan_3 ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## plan_1 ## ]]\n",
            "\n",
            "\n",
            "[[ ## plan_2 ## ]]\n",
            "\n",
            "\n",
            "[[ ## plan_3 ## ]]\n",
            "\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## task ## ]]\n",
            "\n",
            "def solve(s):\n",
            "    \"\"\"You are given a string s.\n",
            "    if s[i] is a letter, reverse its case from lower to upper or vise versa, \n",
            "    otherwise keep it as it is.\n",
            "    If the string contains no letters, reverse the string.\n",
            "    The function should return the resulted string.\n",
            "    Examples\n",
            "    solve(\"1234\") = \"4321\"\n",
            "    solve(\"ab\") = \"AB\"\n",
            "    solve(\"#a@C\") = \"#A@c\"\n",
            "    \"\"\"\n",
            "\n",
            "\n",
            "[[ ## sample_io_prompt ## ]]\n",
            "[1] «assert solve(\"1234\") == \"4321\"»\n",
            "[2] «assert solve(\"ab\") == \"AB\"»\n",
            "[3] «assert solve(\"#a@C\") == \"#A@c\"»\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `[[ ## plan_1 ## ]]`, then `[[ ## plan_2 ## ]]`, then `[[ ## plan_3 ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
            "\n",
            "\n",
            "\u001b[31mResponse:\u001b[0m\n",
            "\n",
            "\u001b[32m[[ ## plan_1 ## ]]\n",
            "1. Initialize an empty result string.\n",
            "2. Iterate through each character in the input string `s`.\n",
            "3. For each character, check if it is a letter:\n",
            "   - If it is a letter, reverse its case (lower to upper or upper to lower) and append it to the result string.\n",
            "   - If it is not a letter, append it to the result string as it is.\n",
            "4. After processing all characters, check if the result string contains any letters:\n",
            "   - If it does, return the result string.\n",
            "   - If it does not, return the reversed version of the original string `s`.\n",
            "\n",
            "[[ ## plan_2 ## ]]\n",
            "1. Create a function `solve(s)` that takes a string `s` as input.\n",
            "2. Use a list comprehension to create a new list where each letter's case is reversed, and non-letter characters are kept the same.\n",
            "3. Join the list into a string.\n",
            "4. Check if the original string `s` contains any letters:\n",
            "   - If it does, return the newly created string.\n",
            "   - If it does not, return the reversed string of `s`.\n",
            "\n",
            "[[ ## plan_3 ## ]]\n",
            "1. Define the function `solve(s)`.\n",
            "2. Initialize a variable `result` to store the transformed characters.\n",
            "3. Loop through each character in `s`:\n",
            "   - Use `str.isalpha()` to check if the character is a letter.\n",
            "   - If it is a letter, use `str.swapcase()` to change its case and add it to `result`.\n",
            "   - If it is not a letter, add it directly to `result`.\n",
            "4. After the loop, check if `result` contains any letters:\n",
            "   - If it does, return `result`.\n",
            "   - If it does not, return the reversed string of `s`.\n",
            "\n",
            "[[ ## completed ## ]]\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lm.inspect_history(n=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07CWEx0XD-10",
        "outputId": "4034c516-a5a1-448e-a705-5910de9bf98a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('self',\n",
              "  Predict(StringSignature(task, sample_io_prompt -> plan_1, plan_2, plan_3\n",
              "      instructions='Given the task description and the sample input-output pairs, generate a structured plan consisting of three actionable steps (Plan 1, Plan 2, Plan 3) to solve the task effectively. Ensure that each plan outlines specific actions that need to be taken to implement the solution correctly.'\n",
              "      task = Field(annotation=str required=True json_schema_extra={'format': <class 'str'>, '__dspy_field_type': 'input', 'prefix': 'Task:', 'desc': '${task}'})\n",
              "      sample_io_prompt = Field(annotation=str required=True json_schema_extra={'format': <class 'str'>, '__dspy_field_type': 'input', 'prefix': 'Sample Io Prompt:', 'desc': '${sample_io_prompt}'})\n",
              "      plan_1 = Field(annotation=str required=True json_schema_extra={'format': <class 'str'>, '__dspy_field_type': 'output', 'prefix': 'Plan 1:', 'desc': '${plan_1}'})\n",
              "      plan_2 = Field(annotation=str required=True json_schema_extra={'format': <class 'str'>, '__dspy_field_type': 'output', 'prefix': 'Plan 2:', 'desc': '${plan_2}'})\n",
              "      plan_3 = Field(annotation=str required=True json_schema_extra={'format': <class 'str'>, '__dspy_field_type': 'output', 'prefix': 'Plan 3:', 'desc': '${plan_3}'})\n",
              "  )))]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "optimized.named_predictors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE7MSdpdGvv2",
        "outputId": "0c26f897-80ce-4346-ac82-ad4e11ad45f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['name', 'description', 'tags', 'difficulty', 'id', 'sample_io', 'test_list'])\n"
          ]
        }
      ],
      "source": [
        "local_path = r\"C:\\Users\\31646\\Desktop\\LLM_Project\\MapCoder\\data\\CodeContest\\Test.jsonl\"\n",
        "colab_path = \"/content/Test.jsonl\"\n",
        "\n",
        "path = local_path\n",
        "\n",
        "codecontest_ds = read_jsonl(path)\n",
        "print(codecontest_ds[0].keys())\n",
        "cc_trainset = random.sample(codecontest_ds, 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "qTZvrrEZHB-c"
      },
      "outputs": [],
      "source": [
        "def cc_evaluate_sample_io(\n",
        "    item: dict,\n",
        "    cur_imp: str,\n",
        "    language: str,\n",
        "):\n",
        "    return contest_evaluate_public_tests(\n",
        "        generated_code=cur_imp,\n",
        "        id=item[\"id\"],\n",
        "        tests=item[\"sample_io_prompt\"],\n",
        "        lang=language\n",
        "  )\n",
        "\n",
        "def cc_metric(example, pred, trace=None):\n",
        "  id = example['id']\n",
        "  sample_io_prompt = f\"## Sample Test cases: \\n{get_sample_io_str(example['sample_io_prompt'])}\\n\"\n",
        "  task = example['task']\n",
        "  algorithm_prompt = \"\"\n",
        "  std_input_prompt = \"\"\n",
        "  for i in range(0,3):\n",
        "    plan = getattr(pred, f\"plan_{i+1}\")\n",
        "    coding_prompt = coding_agent_prompt(algorithm_prompt, task, plan, sample_io_prompt, std_input_prompt)\n",
        "\n",
        "    code, _, _ = gpt_chat(coding_prompt)\n",
        "    code = parse_code(code)\n",
        "    passed, test_log = cc_evaluate_sample_io(example, code, \"python\")\n",
        "\n",
        "    if passed:\n",
        "      return passed\n",
        "  return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOVJRlzIMr7_",
        "outputId": "a74888ca-b561-4717-bc1b-02af9019fd5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example({'id': 1603, 'task': 'For two positive integers l and r (l ≤ r) let c(l, r) denote the number of integer pairs (i, j) such that l ≤ i ≤ j ≤ r and \\\\operatorname{gcd}(i, j) ≥ l. Here, \\\\operatorname{gcd}(i, j) is the [greatest common divisor (GCD)](https://en.wikipedia.org/wiki/Greatest_common_divisor) of integers i and j.\\n\\nYouKn0wWho has two integers n and k where 1 ≤ k ≤ n. Let f(n, k) denote the minimum of ∑_{i=1}^{k}{c(x_i+1,x_{i+1})} over all integer sequences 0=x_1 < x_2 < … < x_{k} < x_{k+1}=n.\\n\\nHelp YouKn0wWho find f(n, k). \\n\\nInput\\n\\nThe first line contains a single integer t (1 ≤ t ≤ 3 ⋅ 10^5) — the number of test cases.\\n\\nThe first and only line of each test case contains two integers n and k (1 ≤ k ≤ n ≤ 10^5). \\n\\nOutput\\n\\nFor each test case, print a single integer — f(n, k).\\n\\nExample\\n\\nInput\\n\\n\\n4\\n6 2\\n4 4\\n3 1\\n10 3\\n\\n\\nOutput\\n\\n\\n8\\n4\\n6\\n11\\n\\nNote\\n\\nIn the first test case, YouKn0wWho can select the sequence [0, 2, 6]. So f(6, 2) = c(1, 2) + c(3, 6) = 3 + 5 = 8 which is the minimum possible.', 'sample_io_prompt': [{'input': '4\\n6 2\\n4 4\\n3 1\\n10 3\\n', 'output': ['8\\n4\\n6\\n11\\n']}], 'plan_1': '', 'plan_2': '', 'plan_3': ''}) (input_keys={'sample_io_prompt', 'task'})\n",
            "[{'input': '4\\n6 2\\n4 4\\n3 1\\n10 3\\n', 'output': ['8\\n4\\n6\\n11\\n']}]\n",
            "For two positive integers l and r (l ≤ r) let c(l, r) denote the number of integer pairs (i, j) such that l ≤ i ≤ j ≤ r and \\operatorname{gcd}(i, j) ≥ l. Here, \\operatorname{gcd}(i, j) is the [greatest common divisor (GCD)](https://en.wikipedia.org/wiki/Greatest_common_divisor) of integers i and j.\n",
            "\n",
            "YouKn0wWho has two integers n and k where 1 ≤ k ≤ n. Let f(n, k) denote the minimum of ∑_{i=1}^{k}{c(x_i+1,x_{i+1})} over all integer sequences 0=x_1 < x_2 < … < x_{k} < x_{k+1}=n.\n",
            "\n",
            "Help YouKn0wWho find f(n, k). \n",
            "\n",
            "Input\n",
            "\n",
            "The first line contains a single integer t (1 ≤ t ≤ 3 ⋅ 10^5) — the number of test cases.\n",
            "\n",
            "The first and only line of each test case contains two integers n and k (1 ≤ k ≤ n ≤ 10^5). \n",
            "\n",
            "Output\n",
            "\n",
            "For each test case, print a single integer — f(n, k).\n",
            "\n",
            "Example\n",
            "\n",
            "Input\n",
            "\n",
            "\n",
            "4\n",
            "6 2\n",
            "4 4\n",
            "3 1\n",
            "10 3\n",
            "\n",
            "\n",
            "Output\n",
            "\n",
            "\n",
            "8\n",
            "4\n",
            "6\n",
            "11\n",
            "\n",
            "Note\n",
            "\n",
            "In the first test case, YouKn0wWho can select the sequence [0, 2, 6]. So f(6, 2) = c(1, 2) + c(3, 6) = 3 + 5 = 8 which is the minimum possible.\n"
          ]
        }
      ],
      "source": [
        "train_data = []\n",
        "for item in cc_trainset:\n",
        "  example = dspy.Example(id = item['id'],task=item['description'], sample_io_prompt = item['sample_io'], plan_1 = \"\", plan_2 = \"\", plan_3 = \"\").with_inputs(\"task\", \"sample_io_prompt\")\n",
        "  train_data.append(example)\n",
        "\n",
        "print(train_data[0])\n",
        "print(train_data[0]['sample_io_prompt'])\n",
        "print(train_data[0]['task'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TpFKMXjkMyQC",
        "outputId": "caddb0b5-50e5-4baf-ba91-9d1cb8c200b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 08:18:57 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "RUNNING WITH THE FOLLOWING LIGHT AUTO RUN SETTINGS:\n",
            "num_trials: 7\n",
            "minibatch: True\n",
            "num_candidates: 5\n",
            "valset size: 80\n",
            "\n",
            "2025/03/06 08:18:58 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
            "2025/03/06 08:18:58 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
            "\n",
            "2025/03/06 08:18:58 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=5 sets of demonstrations...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapping set 1/5\n",
            "Bootstrapping set 2/5\n",
            "Bootstrapping set 3/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 16/20 [05:32<01:23, 20.79s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 4 full traces after 16 examples for up to 1 rounds, amounting to 16 attempts.\n",
            "Bootstrapping set 4/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 6/20 [01:43<04:01, 17.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 3 full traces after 6 examples for up to 1 rounds, amounting to 6 attempts.\n",
            "Bootstrapping set 5/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 6/20 [01:47<04:10, 17.90s/it]\n",
            "2025/03/06 08:28:01 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
            "2025/03/06 08:28:01 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 2 full traces after 6 examples for up to 1 rounds, amounting to 6 attempts.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 08:28:14 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "Proposing instructions...\n",
            "\n",
            "2025/03/06 08:28:55 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
            "\n",
            "2025/03/06 08:28:55 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Given the fields `task`, `sample_io_prompt`, produce the fields `plan_1`, `plan_2`, `plan_3`.\n",
            "\n",
            "2025/03/06 08:28:55 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Given the task of determining how many pairs of positions can be removed from an array while maintaining the mathematical mean of the remaining elements, follow these structured plans:\n",
            "\n",
            "1. **Input Parsing**: Read the number of test cases and for each test case, read the size of the array and the array elements.\n",
            "2. **Calculate Mean**: For each test case, calculate the total sum of the array elements and derive the mean.\n",
            "3. **Determine Valid Pairs**:\n",
            "   - For each unique element in the array, determine if pairs can be formed such that their removal does not alter the mean.\n",
            "   - Use a hashmap to count occurrences of elements and check for valid pairs based on the derived conditions.\n",
            "4. **Count Valid Combinations**: For valid pairs, compute the number of combinations that can be formed and sum these for the final result.\n",
            "5. **Output the Results**: After processing all test cases, print the results for each case.\n",
            "\n",
            "Ensure to handle edge cases, such as when all elements are the same or when no valid pairs exist, and optimize for performance to handle the upper limits of input sizes.\n",
            "\n",
            "2025/03/06 08:28:55 INFO dspy.teleprompt.mipro_optimizer_v2: 2: Given the task of determining the maximum number of cells that can be retained while ensuring that three non-intersecting rectangles can encapsulate selected cells of each color on a checkered sheet, follow these structured plans:\n",
            "\n",
            "1. **Input Parsing**: Read the number of marked cells `n` and the subsequent `n` lines containing the coordinates and colors of the cells.\n",
            "2. **Data Organization**: Separate the cells into three lists based on their colors. This allows for independent processing of each color's cells.\n",
            "3. **Finding Rectangles**: For each color, calculate the bounding rectangle using the minimum and maximum x and y coordinates that encompass all cells of that color.\n",
            "4. **Checking Intersections**: Verify that the rectangles for the three colors do not overlap. This involves comparing the boundaries of the rectangles to ensure they are distinct.\n",
            "5. **Maximizing k**: If the rectangles are non-overlapping, the maximum `k` is `n` (all cells can be retained). If there is an intersection, adjust the count of cells that can be kept for each color to maximize `k`.\n",
            "6. **Output the Result**: Print the maximum value of `k` that can be achieved.\n",
            "\n",
            "Ensure that the implementation efficiently handles edge cases where rectangles may touch at edges but do not overlap.\n",
            "\n",
            "2025/03/06 08:28:55 INFO dspy.teleprompt.mipro_optimizer_v2: 3: Given the task of determining the minimum radius of a circular amusement park that can encompass at least k bird habitats, please produce three distinct plans for solving this problem. Each plan should detail the steps required to compute the distances from the origin to each habitat, sort these distances, and determine the necessary radius based on the sorted distances. Ensure that the plans emphasize efficiency and accuracy in the approach.\n",
            "\n",
            "2025/03/06 08:28:55 INFO dspy.teleprompt.mipro_optimizer_v2: 4: Given the task of restoring an original array `a` from a sorted sums array `b`, analyze the provided input and output to devise structured plans. Your task is to outline three distinct plans that will guide the implementation of the solution. Each plan should break down the steps necessary to achieve the goal, considering edge cases and ensuring efficiency. Utilize the sample input/output provided to inform your plans and ensure clarity in your approach.\n",
            "\n",
            "2025/03/06 08:28:55 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2025/03/06 08:28:55 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
            "2025/03/06 08:28:55 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
            "\n",
            "2025/03/06 08:28:55 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 8 - Full Evaluation of Default Program ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 19.00 / 80 (23.8%): 100%|██████████| 80/80 [04:51<00:00,  3.64s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 08:33:47 INFO dspy.evaluate.evaluate: Average Metric: 19 / 80 (23.8%)\n",
            "2025/03/06 08:33:47 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 23.75\n",
            "\n",
            "2025/03/06 08:33:47 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 2 / 8 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 3.00 / 25 (12.0%): 100%|██████████| 25/25 [01:58<00:00,  4.72s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 08:35:45 INFO dspy.evaluate.evaluate: Average Metric: 3 / 25 (12.0%)\n",
            "2025/03/06 08:35:45 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 12.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/03/06 08:35:45 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [12.0]\n",
            "2025/03/06 08:35:45 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [23.75]\n",
            "2025/03/06 08:35:45 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 23.75\n",
            "2025/03/06 08:35:45 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/03/06 08:35:45 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 3 / 8 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 5.00 / 25 (20.0%): 100%|██████████| 25/25 [02:14<00:00,  5.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 08:37:59 INFO dspy.evaluate.evaluate: Average Metric: 5 / 25 (20.0%)\n",
            "2025/03/06 08:37:59 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 20.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/03/06 08:37:59 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [12.0, 20.0]\n",
            "2025/03/06 08:37:59 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [23.75]\n",
            "2025/03/06 08:37:59 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 23.75\n",
            "2025/03/06 08:37:59 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/03/06 08:37:59 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 4 / 8 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 9.00 / 25 (36.0%): 100%|██████████| 25/25 [01:41<00:00,  4.08s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 08:39:41 INFO dspy.evaluate.evaluate: Average Metric: 9 / 25 (36.0%)\n",
            "2025/03/06 08:39:41 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 36.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/03/06 08:39:41 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [12.0, 20.0, 36.0]\n",
            "2025/03/06 08:39:41 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [23.75]\n",
            "2025/03/06 08:39:41 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 23.75\n",
            "2025/03/06 08:39:41 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/03/06 08:39:41 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 5 / 8 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 6.00 / 25 (24.0%): 100%|██████████| 25/25 [01:58<00:00,  4.74s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 08:41:40 INFO dspy.evaluate.evaluate: Average Metric: 6 / 25 (24.0%)\n",
            "2025/03/06 08:41:40 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 24.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/03/06 08:41:40 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [12.0, 20.0, 36.0, 24.0]\n",
            "2025/03/06 08:41:40 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [23.75]\n",
            "2025/03/06 08:41:40 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 23.75\n",
            "2025/03/06 08:41:40 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/03/06 08:41:40 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 6 / 8 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 3.00 / 25 (12.0%): 100%|██████████| 25/25 [01:44<00:00,  4.18s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 08:43:24 INFO dspy.evaluate.evaluate: Average Metric: 3 / 25 (12.0%)\n",
            "2025/03/06 08:43:24 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 12.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 3'].\n",
            "2025/03/06 08:43:24 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [12.0, 20.0, 36.0, 24.0, 12.0]\n",
            "2025/03/06 08:43:24 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [23.75]\n",
            "2025/03/06 08:43:24 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 23.75\n",
            "2025/03/06 08:43:24 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/03/06 08:43:24 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 7 / 8 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 8.00 / 25 (32.0%): 100%|██████████| 25/25 [01:56<00:00,  4.64s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 08:45:20 INFO dspy.evaluate.evaluate: Average Metric: 8 / 25 (32.0%)\n",
            "2025/03/06 08:45:20 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 32.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/03/06 08:45:20 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [12.0, 20.0, 36.0, 24.0, 12.0, 32.0]\n",
            "2025/03/06 08:45:20 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [23.75]\n",
            "2025/03/06 08:45:20 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 23.75\n",
            "2025/03/06 08:45:20 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/03/06 08:45:20 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 8 / 8 - Full Evaluation =====\n",
            "2025/03/06 08:45:20 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 36.0) from minibatch trials...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 24.00 / 80 (30.0%): 100%|██████████| 80/80 [05:04<00:00,  3.80s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 08:50:25 INFO dspy.evaluate.evaluate: Average Metric: 24 / 80 (30.0%)\n",
            "2025/03/06 08:50:25 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mNew best full eval score!\u001b[0m Score: 30.0\n",
            "2025/03/06 08:50:25 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [23.75, 30.0]\n",
            "2025/03/06 08:50:25 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 30.0\n",
            "2025/03/06 08:50:25 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
            "2025/03/06 08:50:25 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2025/03/06 08:50:25 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 30.0!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "tp = dspy.MIPROv2(metric=cc_metric, auto='light')\n",
        "optimized = tp.compile(generatePlans, trainset=train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuVlsPUwNQ25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Given the task of restoring an original array `a` from a sorted sums array `b`,\n",
            "analyze the provided input and output to devise structured plans. Your task is\n",
            "to outline three distinct plans that will guide the implementation of the\n",
            "solution. Each plan should break down the steps necessary to achieve the goal,\n",
            "considering edge cases and ensuring efficiency. Utilize the sample input/output\n",
            "provided to inform your plans and ensure clarity in your approach.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "wrapped_text = textwrap.fill(optimized.signature.instructions, width=80)  # 80 可调整\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('self',\n",
              "  Predict(StringSignature(task, sample_io_prompt -> plan_1, plan_2, plan_3\n",
              "      instructions='Given the task of restoring an original array `a` from a sorted sums array `b`, analyze the provided input and output to devise structured plans. Your task is to outline three distinct plans that will guide the implementation of the solution. Each plan should break down the steps necessary to achieve the goal, considering edge cases and ensuring efficiency. Utilize the sample input/output provided to inform your plans and ensure clarity in your approach.'\n",
              "      task = Field(annotation=str required=True json_schema_extra={'format': <class 'str'>, '__dspy_field_type': 'input', 'prefix': 'Task:', 'desc': '${task}'})\n",
              "      sample_io_prompt = Field(annotation=str required=True json_schema_extra={'format': <class 'str'>, '__dspy_field_type': 'input', 'prefix': 'Sample Io Prompt:', 'desc': '${sample_io_prompt}'})\n",
              "      plan_1 = Field(annotation=str required=True json_schema_extra={'format': <class 'str'>, '__dspy_field_type': 'output', 'prefix': 'Plan 1:', 'desc': '${plan_1}'})\n",
              "      plan_2 = Field(annotation=str required=True json_schema_extra={'format': <class 'str'>, '__dspy_field_type': 'output', 'prefix': 'Plan 2:', 'desc': '${plan_2}'})\n",
              "      plan_3 = Field(annotation=str required=True json_schema_extra={'format': <class 'str'>, '__dspy_field_type': 'output', 'prefix': 'Plan 3:', 'desc': '${plan_3}'})\n",
              "  )))]"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "optimized.named_predictors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mapcoder",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
